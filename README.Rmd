---
title: "ERSST"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ersst

Provides for download, archiving and access to [errst](https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v5) online and local datasets.

### [Citation](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00927)

```
Boyin Huang, Peter W. Thorne, Viva F. Banzon, Tim Boyer, Gennady Chepurin, Jay H. Lawrimore, Matthew J. Menne, Thomas M. Smith, Russell S. Vose, and Huai-Min Zhang (2017): NOAA Extended Reconstructed Sea Surface Temperature (ERSST), Version 5. NOAA National Centers for Environmental Information. doi:10.7289/V5T72FNM [access date, monthly from 2021-04-15].
```

### Requirements

  + [R v4+](https://www.r-project.org/)
  + [rlang](https://CRAN.R-project.org/package=rlang)
  + [dplyr](https://CRAN.R-project.org/package=dplyr)
  + [readr](https://CRAN.R-project.org/package=readr)
  + [terra](https://CRAN.R-project.org/package=terra)
  + [xml2](https://CRAN.R-project.org/package=xml2)
  + [httr](https://CRAN.R-project.org/package=httr)
  + [rvest](https://github.com/BigelowLab/rvest)
  

### Installation

```
remotes::install_github("BigelowLab/ersst")
```


```{r}
suppressPackageStartupMessages({
  library(dplyr)
  library(sf)
  library(ersst)
  library(xyzt)
  library(stars)
})
```

#### Working with points.  

See the [xyzt](https://github.com/BigelowLab/xyzt) package for more details on the example Southern US Atlantic Bight data.

```{r}
# read in example SAB points
x <- xyzt::read_sab() |>
  dplyr::select(-time, -depth) |>
  dplyr::mutate(lon = xyzt::to_360(lon)) |>
  xyzt::as_POINT()

# generate a ersst url for a given date
url <- ersst_url("2018-12-18")

# download
temp_file <- tempfile(fileext = ".nc")
ok <- download.file(url, temp_file)

# open the resource
X <- ncdf4::nc_open(temp_file)

# extract the data 
covars <- ersst::extract(x, X, varname = ersst_vars(X))

# bind to the input
(y <- dplyr::bind_cols(x, covars))
```

#### Working with bounding boxes (from points or polygons). 

Learn more about working with [stars](https://CRAN.R-project.org/package=stars) objects in the [vignettes](https://r-spatial.github.io/stars/).

```{r}
# read in example SAB points
x <- xyzt::read_sab() |>
  dplyr::select(-time, -depth) |>
  dplyr::mutate(lon = xyzt::to_360(lon)) |>
  xyzt::as_BBOX()

(covars <- ersst::extract(x, X, varnames = ersst::ersst_vars(X)))
```

Now let's see what it looks like.

```{r}
x <- xyzt::read_sab() |>
  dplyr::select(-time, -depth) |>
  dplyr::mutate(lon = xyzt::to_360(lon)) |>
  xyzt::as_POINT()
par(mfrow = c(1,2))
plot(covars, attr = 'sst', axes = TRUE, reset = FALSE)
plot(sf::st_geometry(x), add = TRUE, col = "orange", pch = 19, cex = 2)
```



```{r}
# cleanup
ncdf4::nc_close(X)
```


### Old README

### List available file online

It is easy to generate a listing of data files, organized by month, that are [available online](https://www.ncei.noaa.gov/pub/data/cmb/ersst/v5/netcdf/).

```{r list, message = FALSE}
library(dplyr)
library(ersst)

online_db <- ncdc_list_available(version = "v5", verbose = TRUE)
online_db
```

The anomaly column indicates if the file is for `sst` or `sst anomaly` - a bit of a red herring in this case.  It will become important later, but in the meantime know that each online file contains 2 layers: `sst` or `sst anomaly (ssta)`.  The anomaly computation is [discussed here](https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v5).


### Download online data

For a URL by date and version, then download.

```{r download_one}
uri <- ncdc_build_uri(as.Date("1995-12-18"), version = "v5")
# [1] "https://www.ncei.noaa.gov/pub/data/cmb/ersst/v5/netcdf/ersst.v5.20199512.nc"
ok <- download_ersst(uri, path = ".", verbose = TRUE)
ok
```

Each file contains 2 layers: `sst` and `ssta`

```{r read_and_show}
library(stars)
s <- read_stars(names(ok))
s
```

### Download a series, unpack and save

If you are developing a local repository of the data, you can use built-in capabilities of `fetch_ersst()`. Each layer is saved separately as either `ersst.vv.YYYYmm.tif` or `erssta.vv.YYYYmm.tif`.  Returned is a database of the fetched-and-stored contents. Note that you can pass in the available online database listing; this just saves the time needed to repeat the query.

```{r download_suite}
root_path <- "~/ersst_data"
dates <- seq(from = as.Date("2020-11-15"), by = "month", length = 4)
db <- fetch_ersst(dates, version = 'v5', path = root_path, verbose = TRUE, avail_db = online_db)
db
```

You will likely want to save this database. Note that it is best to save it with the version.  Who knows when the next version will be released, but best practice is to be ready for it. If you have an existing database, you can append the new database to it before saving (see `append_database`).

```{r save_database}
v5_path <- ersst_path("v5", root = root_path)
db <- write_database(db, v5_path)
```

### Using the local database

If you have kept a database file (and if you mess your up, see `build_database()`) then you can use it to easily find the files you want without having to search the directories.

```{r filter_database}
library(stars)
sub_db <- read_database(v5_path) %>%
  filter(anomaly == TRUE, 
         between(date, as.Date("2020-11-01"), as.Date("2021-02-01")))
sub_filenames <- compose_filename(sub_db, root_path)
ss <- read_stars(sub_filenames, along = "band")
breaks <- 11
plot(ss, 
     main = format(sub_db$date, "anomaly %Y-%b"),
     col = heat.colors(breaks))
```
